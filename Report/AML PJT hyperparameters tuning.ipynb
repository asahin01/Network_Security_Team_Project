{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "traindata= pd.read_csv('C:/Users/amatu/Documents/train_imperson_without4n7_balanced_data.csv')\n",
    "testdata= pd.read_csv('C:/Users/amatu/Documents/test_imperson_without4n7_balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "\n",
    "X_train, Y_train = traindata.loc[:, traindata.columns != '155'], traindata['155']\n",
    "\n",
    "X_test, Y_test = testdata.loc[:, testdata.columns != '155'], testdata['155']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required modules\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1: Var Threshold, Kbest  f_classif, AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__learning_rate': 0.01, 'ada__n_estimators': 100, 'top features__k': 35}\n",
      "0.9389967437451053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('top features', SelectKBest(f_classif)),\n",
    "    ('ada',AdaBoostClassifier())])\n",
    "\n",
    "\n",
    "grid=GridSearchCV(cv=10,\n",
    "            estimator=pipeline1,\n",
    "              param_grid={'ada__n_estimators': [10,50,100,150],\n",
    "                  'ada__learning_rate':[0.001,0.1,0.01],\n",
    "                   'top features__k':[15,20,30,35]},\n",
    "                  scoring = 'accuracy',\n",
    "                 n_jobs=-1)\n",
    "    \n",
    "    \n",
    "grid.fit(X_train, Y_train)\n",
    "#sorted(pipeline1.get_params().keys()) list of the parameters you can tune \n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.07614921061806"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#optimizing k produces a model overfitting train performing poorly on test\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('top20 features', SelectKBest(f_classif, k=20)),\n",
    "    ('ada',AdaBoostClassifier(n_estimators = 150, learning_rate = 0.1))])\n",
    "\n",
    "\n",
    "pipeline1.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_predict=pipeline1.predict(X_test)\n",
    "accuracy_score(Y_test, Y_predict)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline2: Var Threshold, Normalizer, Kbest20 chi2, logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amatu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 1000, 'top features__k': 20}\n",
      "0.98313136309303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipeline2= Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('norm 1', Normalizer()),\n",
    "    ('top features', SelectKBest(chi2)),\n",
    "    ('model',LogisticRegression())])\n",
    "\n",
    "\n",
    "grid=GridSearchCV(cv=10,\n",
    "            estimator=pipeline2,\n",
    "             param_grid={'top features__k':[15,20,30,35],\n",
    "                 'model__C': [0.01, 0.1, 1, 10, 100, 1000]},\n",
    "                  scoring = 'accuracy',\n",
    "                 n_jobs=-1)\n",
    "    \n",
    "    \n",
    "grid.fit(X_train, Y_train)\n",
    "# sorted(pipeline2.get_params().keys()) #list of the parameters you can tune \n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amatu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88.75691020469147"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2= Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('norm 1', Normalizer()),\n",
    "    ('top20 features', SelectKBest(chi2, k=20)),\n",
    "    ('model',LogisticRegression(C = 1000))])\n",
    "\n",
    "\n",
    "\n",
    "pipeline2.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_predict=pipeline2.predict(X_test)\n",
    "accuracy_score(Y_test, Y_predict)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2a: Var Threshold, MinMax, Kbest20 chi2, logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amatu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 1000, 'top features__k': 20}\n",
      "0.9875520382506904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline2a= Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('minmax', MinMaxScaler()),\n",
    "    ('top features', SelectKBest(chi2)),\n",
    "    ('model',LogisticRegression())])\n",
    "\n",
    "\n",
    "grid=GridSearchCV(cv=10,\n",
    "            estimator=pipeline2a,\n",
    "             param_grid={'top features__k':[15,20,30,35],'model__C': [0.01, 0.1, 1, 10, 100, 1000]},\n",
    "                  scoring = 'accuracy',\n",
    "                 n_jobs=-1)\n",
    "    \n",
    "    \n",
    "grid.fit(X_train, Y_train)\n",
    "#sorted(pipeline1.get_params().keys()) #list of the parameters you can tune \n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amatu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.59056725932567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2a= Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('minmax', MinMaxScaler()),\n",
    "    ('top20 features', SelectKBest(chi2, k=20)),\n",
    "    ('model',LogisticRegression(C=1000))])\n",
    "\n",
    "\n",
    "pipeline2a.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "Y_predict=pipeline2a.predict(X_test)\n",
    "accuracy_score(Y_test, Y_predict)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3: Var Threshold, MinMax, Kbest30 chi2, Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__learning_rate': 0.01, 'ada__n_estimators': 100, 'top features__k': 35}\n",
      "0.9389967437451053\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('scale 0_1', MinMaxScaler()),\n",
    "    ('top features', SelectKBest(f_classif)),\n",
    "    ('ada',AdaBoostClassifier())])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid=GridSearchCV(cv=10,\n",
    "            estimator=pipeline3,\n",
    "              param_grid={'ada__n_estimators': [10,50,100,150],\n",
    "                  'ada__learning_rate':[0.001,0.1,0.01],\n",
    "                         'top features__k':[15,20,30,35]},\n",
    "                  scoring = 'accuracy',\n",
    "                 n_jobs=-1)\n",
    "    \n",
    "    \n",
    "grid.fit(X_train, Y_train)\n",
    "#sorted(pipeline1.get_params().keys()) #list of the parameters you can tune \n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.91677872404004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('scale 0_1', MinMaxScaler()),\n",
    "    ('top20 features', SelectKBest(f_classif, k=30)),\n",
    "    ('ada',AdaBoostClassifier(n_estimators=150,learning_rate=0.1))])\n",
    "\n",
    "pipeline3.fit(X_train,Y_train)\n",
    "\n",
    "Y_predict=pipeline3.predict(X_test)\n",
    "accuracy_score(Y_test, Y_predict)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different optimum learning rate actually yields worse performance on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('zero variance', VarianceThreshold()),\n",
    "    ('scale 0_1', MinMaxScaler()),\n",
    "    ('top20 features', SelectKBest(f_classif, k=35)),\n",
    "    ('ada',AdaBoostClassifier(n_estimators=100,learning_rate=0.01))])\n",
    "\n",
    "pipeline3.fit(X_train,Y_train)\n",
    "\n",
    "Y_predict=pipeline3.predict(X_test)\n",
    "accuracy_score(Y_test, Y_predict)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
