{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata= pd.read_csv('datasets/train_imperson_without4n7_balanced_data.csv')\n",
    "mdata_test= pd.read_csv('datasets/test_imperson_without4n7_balanced_data.csv')\n",
    "Xtest, Ytest = mdata_test.loc[:, mdata_test.columns != '155'], mdata_test['155']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3         5         6         8         9  10  11  12  ...  146  147  \\\n",
       "0  0  0  0  0.000066  0.000066  0.009150  0.009150   0   0   0  ...  0.0    0   \n",
       "1  0  0  0  0.000014  0.000014  0.000000  0.000000   0   0   0  ...  0.0    0   \n",
       "2  0  0  0  0.035528  0.035528  0.070588  0.070588   0   0   0  ...  0.0    0   \n",
       "3  0  0  0  0.005128  0.005128  0.094771  0.094771   0   0   0  ...  0.0    0   \n",
       "4  0  0  0  0.035116  0.035116  0.070588  0.070588   0   0   0  ...  0.0    0   \n",
       "\n",
       "   148  149  150  151  152  153  154  155  \n",
       "0    0    0    0    0    0    0  0.0    0  \n",
       "1    0    0    0    0    0    0  0.0    0  \n",
       "2    0    0    0    0    0    0  0.0    0  \n",
       "3    0    0    0    0    0    0  0.0    0  \n",
       "4    0    0    0    0    0    0  0.0    0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97044 entries, 0 to 97043\n",
      "Columns: 153 entries, 1 to 155\n",
      "dtypes: float64(48), int64(105)\n",
      "memory usage: 113.3 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#investigating presence of missing data\n",
    "\n",
    "mdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97044 entries, 0 to 97043\n",
      "Columns: 153 entries, 1 to 155\n",
      "dtypes: float64(48), int64(105)\n",
      "memory usage: 114.0 MB\n"
     ]
    }
   ],
   "source": [
    "#data is complete\n",
    "\n",
    "m1= mdata.dropna()\n",
    "m1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96497 entries, 0 to 97043\n",
      "Columns: 153 entries, 1 to 155\n",
      "dtypes: float64(48), int64(105)\n",
      "memory usage: 113.4 MB\n"
     ]
    }
   ],
   "source": [
    "#investigating presence of duplicate values\n",
    "#is this because Dr Yoo rebalanced the classes with some form of bootstrapping? Hence we leave them in?\n",
    "#I think we should assume data are iid anyway, hence keep duplicates\n",
    "#if later we can see that the model does nt generalize well we can go back and eliminate them.\n",
    "\n",
    "\n",
    "m2 = mdata.drop_duplicates()\n",
    "m2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3         5         6    8    9  10  11  12  ...  146  147  148  \\\n",
       "307    0  0  0  0.000017  0.000017  0.0  0.0   0   0   0  ...  0.0    0    0   \n",
       "772    0  0  0  0.000011  0.000011  0.0  0.0   0   0   0  ...  0.0    0    0   \n",
       "1565   0  0  0  0.000014  0.000014  0.0  0.0   0   0   0  ...  0.0    0    0   \n",
       "7708   0  0  0  0.000037  0.000037  0.0  0.0   0   0   0  ...  0.0    0    0   \n",
       "13105  0  0  0  0.000011  0.000011  0.0  0.0   0   0   0  ...  0.0    0    0   \n",
       "\n",
       "       149  150  151  152  153  154  155  \n",
       "307      0    0    0    0    0  0.0    0  \n",
       "772      0    0    0    0    0  0.0    0  \n",
       "1565     0    0    0    0    0  0.0    0  \n",
       "7708     0    0    0    0    0  0.0    0  \n",
       "13105    0    0    0    0    0  0.0    0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicate rows for reference\n",
    "\n",
    "mdata[mdata.duplicated() == True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>0.150720</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.111776</td>\n",
       "      <td>0.144825</td>\n",
       "      <td>0.170367</td>\n",
       "      <td>0.442533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315662</td>\n",
       "      <td>0.124710</td>\n",
       "      <td>0.120557</td>\n",
       "      <td>0.301584</td>\n",
       "      <td>0.334706</td>\n",
       "      <td>0.357250</td>\n",
       "      <td>0.482821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>97044.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std         min         25%         50%  \\\n",
       "count    153.0  153.000000  153.000000  153.000000  153.000000  153.000000   \n",
       "mean   97044.0    0.150720    0.058346    0.016340    0.111776    0.144825   \n",
       "std        0.0    0.315662    0.124710    0.120557    0.301584    0.334706   \n",
       "min    97044.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    97044.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    97044.0    0.000008    0.000004    0.000000    0.000000    0.000000   \n",
       "75%    97044.0    0.037225    0.017885    0.000000    0.000000    0.000000   \n",
       "max    97044.0    1.000000    0.500003    1.000000    1.000000    1.000000   \n",
       "\n",
       "              75%         max  \n",
       "count  153.000000  153.000000  \n",
       "mean     0.170367    0.442533  \n",
       "std      0.357250    0.482821  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.001530  \n",
       "75%      0.002253    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.describe().T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate X and Y\n",
    "\n",
    "X, Y = mdata.loc[:, mdata.columns != '155'], mdata['155']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.387493   0.326894   0.09642841]\n",
      "[[ 6.29469163e-18 -4.17130067e-22 -5.74163967e-25 -2.97094541e-03\n",
      "  -2.97094541e-03  3.00028440e-01  3.00028440e-01  6.62590687e-31\n",
      "   1.43584482e-30 -2.16504650e-30 -8.24557519e-33  1.73281500e-04\n",
      "   1.73281500e-04  1.73281500e-04  0.00000000e+00  1.73281500e-04\n",
      "   0.00000000e+00  1.73281500e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.73281500e-04\n",
      "   0.00000000e+00  0.00000000e+00  1.73281500e-04  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.01130730e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.73281500e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   3.60897660e-01  1.70542279e-04  0.00000000e+00 -3.70651046e-01\n",
      "   3.70824327e-01  1.73281500e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.02140111e-02  1.73281500e-04\n",
      "   0.00000000e+00  1.73243421e-01  0.00000000e+00  2.17324963e-01\n",
      "   5.14081961e-02  2.18154841e-01  0.00000000e+00 -2.91530822e-02\n",
      "  -1.03688950e-01  2.21857467e-04  2.40345471e-01  0.00000000e+00\n",
      "  -1.13963617e-03 -9.01230652e-04 -5.53431552e-03 -4.35482145e-04\n",
      "  -1.11535214e-03  3.05065126e-05  0.00000000e+00  9.16087986e-02\n",
      "  -1.84816830e-05 -3.06317561e-05  0.00000000e+00 -4.91134391e-05\n",
      "   0.00000000e+00 -2.33820570e-06  1.73281500e-04 -1.25741208e-01\n",
      "   0.00000000e+00  0.00000000e+00 -7.87385439e-02 -4.05698525e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.58957107e-05 -1.24312185e-01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.98247269e-03 -1.58459439e-05 -8.40801491e-04\n",
      "  -3.51549684e-03 -1.75976322e-04 -9.51272205e-04 -7.54356931e-06\n",
      "  -4.79569975e-04 -2.35008678e-03 -1.40291748e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.67672362e-06 -1.29344497e-01\n",
      "  -4.29818902e-04 -5.37280015e-02 -3.05950166e-05 -2.63043978e-04\n",
      "  -8.98168344e-04  0.00000000e+00 -7.24883193e-04 -4.94760283e-07\n",
      "  -2.52102225e-04 -9.58697720e-07 -5.07611199e-07 -3.21272911e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.58957107e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.04037005e-06\n",
      "   0.00000000e+00  1.45588302e-01 -6.65644320e-04  1.48839206e-01\n",
      "  -9.89035274e-04  2.74775893e-04  5.33062648e-02  5.33062648e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.10752537e-01]\n",
      " [ 6.24102570e-17  1.16901883e-21 -9.16113671e-24  1.47524177e-03\n",
      "   1.47524177e-03  7.95202557e-02  7.95202557e-02 -2.31515064e-30\n",
      "  -1.92453443e-30  1.00290434e-29  2.95009532e-32 -2.97516310e-04\n",
      "  -2.97516310e-04 -2.97516310e-04  0.00000000e+00 -2.97516310e-04\n",
      "   0.00000000e+00 -2.97516310e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.97516310e-04\n",
      "   0.00000000e+00  0.00000000e+00 -2.97516310e-04  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.73318512e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.97516310e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.58207506e-01 -2.91615372e-04  0.00000000e+00 -2.28685420e-01\n",
      "   2.28387903e-01 -2.97516310e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.13821748e-02 -2.97516310e-04\n",
      "   0.00000000e+00 -1.09712554e-01  0.00000000e+00 -3.08359878e-01\n",
      "   3.87698862e-01 -4.03915271e-01  0.00000000e+00  8.32328950e-02\n",
      "  -3.96062314e-01 -3.92757662e-04 -3.93922369e-01  0.00000000e+00\n",
      "   2.98540795e-03  2.84404359e-03  1.87850336e-02  1.98151962e-04\n",
      "  -1.81725616e-03 -2.09965619e-04  0.00000000e+00  1.03645557e-01\n",
      "   1.57743837e-05  6.61061479e-05  0.00000000e+00  8.18805316e-05\n",
      "   0.00000000e+00  1.88815490e-05 -2.97516310e-04  1.39867767e-01\n",
      "   0.00000000e+00  0.00000000e+00  8.91812298e-02  4.55725528e-02\n",
      "   0.00000000e+00  0.00000000e+00  1.76165390e-05  1.38177276e-01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.64320388e-03  1.53830269e-05  1.04678894e-03\n",
      "   4.11610550e-03  1.98415229e-04  9.21653687e-04  9.54869382e-06\n",
      "   5.64966393e-04  2.73677294e-03  1.64474987e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  5.17891776e-06  1.43812847e-01\n",
      "   4.47456698e-04  6.05281322e-02  3.58274654e-05  3.10470223e-04\n",
      "   1.04473297e-03  0.00000000e+00  8.56926378e-04  5.81380991e-07\n",
      "   2.96230973e-04  1.12671982e-06  5.96481796e-07  3.77520124e-02\n",
      "   0.00000000e+00  0.00000000e+00  1.76165390e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.69428481e-06\n",
      "   0.00000000e+00 -1.11714377e-01 -2.10574840e-03 -1.07245842e-01\n",
      "  -3.10013887e-03  1.00166435e-04  1.46374622e-02  1.46374622e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  7.46068024e-02]\n",
      " [-1.02878204e-17  4.36804752e-17 -1.34600318e-20  9.02010567e-03\n",
      "   9.02010567e-03  2.40486169e-01  2.40486169e-01  1.00001013e-25\n",
      "  -7.63374542e-26 -4.08789644e-26  4.43872391e-28  1.42528465e-05\n",
      "   1.42528465e-05  1.42528465e-05  0.00000000e+00  1.42528465e-05\n",
      "   0.00000000e+00  1.42528465e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.42528465e-05\n",
      "   0.00000000e+00  0.00000000e+00  1.42528465e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.67273853e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.42528465e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.61192871e-02  1.06701922e-05  0.00000000e+00  1.42699462e-01\n",
      "  -1.42685209e-01  1.42528465e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -4.09026024e-02  1.42528465e-05\n",
      "   0.00000000e+00 -1.13553118e-01  0.00000000e+00 -6.02030474e-02\n",
      "  -2.36146104e-01  1.87887754e-01  0.00000000e+00 -9.61581398e-02\n",
      "  -9.71242515e-03  8.23975950e-06  1.56406989e-01  0.00000000e+00\n",
      "  -1.59136048e-03 -7.86204101e-04  5.23279243e-03  7.57200132e-04\n",
      "   7.29466078e-04  6.89404215e-04  0.00000000e+00  1.67517249e-01\n",
      "  -4.06290229e-05 -1.63068608e-04  0.00000000e+00 -2.03697631e-04\n",
      "   0.00000000e+00 -4.54740154e-05  1.42528465e-05  3.98075497e-01\n",
      "   0.00000000e+00  0.00000000e+00  2.65478285e-01  1.42131668e-01\n",
      "   0.00000000e+00  0.00000000e+00  5.20040507e-05  3.94764281e-01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.63798585e-02  5.76302651e-05 -2.48467679e-04\n",
      "   1.28778570e-02  5.55153933e-04  3.12359304e-03 -1.58303242e-05\n",
      "  -2.11652311e-04 -2.78653545e-03 -3.20775964e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.32927858e-05  3.98903778e-01\n",
      "   7.97944242e-04  1.67830897e-01  1.02514673e-04  9.15409073e-04\n",
      "   3.06411749e-03  0.00000000e+00  2.66392115e-03  1.85453688e-06\n",
      "   9.44909045e-04  3.59761815e-06  1.90270667e-06  1.20424473e-01\n",
      "   0.00000000e+00  0.00000000e+00  5.20040507e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.97615393e-05\n",
      "   0.00000000e+00  9.42053920e-02  7.77817178e-04  8.75703022e-02\n",
      "   1.07768604e-03 -3.89001051e-04  3.53206291e-02  3.53206291e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.12201191e-01]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True  True False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False  True  True False  True\n",
      "  True False False False False False False False False False  True False\n",
      " False  True False  True  True  True False  True  True  True  True False\n",
      "  True  True  True  True  True  True False  True False False False  True\n",
      " False  True False  True False False  True  True False False  True  True\n",
      " False False False False False  True  True  True  True  True  True  True\n",
      "  True  True False False False False  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True False False False False\n",
      " False False False False False  True  True  True  True  True  True  True\n",
      " False False False False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_>0)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.702% (10.173%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression without any preprocessing or feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     20079\n",
      "           1       0.95      0.79      0.86     20079\n",
      "\n",
      "    accuracy                           0.87     40158\n",
      "   macro avg       0.88      0.87      0.87     40158\n",
      "weighted avg       0.88      0.87      0.87     40158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model = LogisticRegression()\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.232% (0.035%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate features with 0 standard deviation\n",
    "#Xselected with 0 var taken out\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "X5=selector.fit(X)\n",
    "col = X.columns[selector.get_support()]\n",
    "Xselected= X.loc[:, col ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizer transform norm 1\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer().fit(Xselected)\n",
    "normalizedX2 = scaler.transform(Xselected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised range 0 1\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "scaler1 = MinMaxScaler().fit(Xselected)\n",
    "scaled0_1=scaler1.transform(Xselected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:121: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "//anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:122: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "#Power and quantile transform. THe latter distorts correlation, hence try the former\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method = 'yeo-johnson').fit(Xselected)\n",
    "poweredX2 = pt.transform(Xselected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>133</th>\n",
       "      <th>138</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>0.233105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          5         6         8         9        14        15        16  \\\n",
       "0  0.000015  0.000015  0.002125  0.002125  0.232240  0.232240  0.232240   \n",
       "1  0.000004  0.000004  0.000000  0.000000  0.252240  0.252240  0.252240   \n",
       "2  0.008282  0.008282  0.016454  0.016454  0.233105  0.233105  0.233105   \n",
       "3  0.001145  0.001145  0.021168  0.021168  0.223356  0.223356  0.223356   \n",
       "4  0.008178  0.008178  0.016439  0.016439  0.232884  0.232884  0.232884   \n",
       "\n",
       "         18        20        26  ...  133       138  140  141  142  143  144  \\\n",
       "0  0.232240  0.232240  0.232240  ...  0.0  0.116120  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.252240  0.252240  0.252240  ...  0.0  0.126120  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.233105  0.233105  0.233105  ...  0.0  0.116553  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.223356  0.223356  0.223356  ...  0.0  0.111678  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.232884  0.232884  0.232884  ...  0.0  0.116442  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   145  146  154  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datframe wiht norm 1\n",
    "\n",
    "NX2df = pd.DataFrame(normalizedX2, columns = Xselected.columns)\n",
    "\n",
    "NX2df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8196847568828263"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(NX2df.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>133</th>\n",
       "      <th>138</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.527311</td>\n",
       "      <td>-1.527311</td>\n",
       "      <td>-0.883721</td>\n",
       "      <td>-0.883721</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151287</td>\n",
       "      <td>-0.105837</td>\n",
       "      <td>-1.165737</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.788655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.553062</td>\n",
       "      <td>-1.553062</td>\n",
       "      <td>-1.090489</td>\n",
       "      <td>-1.090489</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151287</td>\n",
       "      <td>-0.105837</td>\n",
       "      <td>-1.165737</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.788655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.623799</td>\n",
       "      <td>2.623799</td>\n",
       "      <td>0.166931</td>\n",
       "      <td>0.166931</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151287</td>\n",
       "      <td>-0.105837</td>\n",
       "      <td>-1.165737</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.788655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371013</td>\n",
       "      <td>0.371013</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151287</td>\n",
       "      <td>-0.105837</td>\n",
       "      <td>-1.165737</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.788655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.620509</td>\n",
       "      <td>2.620509</td>\n",
       "      <td>0.166931</td>\n",
       "      <td>0.166931</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151287</td>\n",
       "      <td>-0.105837</td>\n",
       "      <td>-1.165737</td>\n",
       "      <td>-0.105657</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.45347</td>\n",
       "      <td>-0.788655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          5         6         8         9        14        15        16  \\\n",
       "0 -1.527311 -1.527311 -0.883721 -0.883721  0.014712  0.014712  0.014712   \n",
       "1 -1.553062 -1.553062 -1.090489 -1.090489  0.014712  0.014712  0.014712   \n",
       "2  2.623799  2.623799  0.166931  0.166931  0.014712  0.014712  0.014712   \n",
       "3  0.371013  0.371013  0.458800  0.458800  0.014712  0.014712  0.014712   \n",
       "4  2.620509  2.620509  0.166931  0.166931  0.014712  0.014712  0.014712   \n",
       "\n",
       "         18        20        26  ...      133  138       140       141  \\\n",
       "0  0.014712  0.014712  0.014712  ... -0.00321  0.0 -1.151287 -0.105837   \n",
       "1  0.014712  0.014712  0.014712  ... -0.00321  0.0 -1.151287 -0.105837   \n",
       "2  0.014712  0.014712  0.014712  ... -0.00321  0.0 -1.151287 -0.105837   \n",
       "3  0.014712  0.014712  0.014712  ... -0.00321  0.0 -1.151287 -0.105837   \n",
       "4  0.014712  0.014712  0.014712  ... -0.00321  0.0 -1.151287 -0.105837   \n",
       "\n",
       "        142       143       144      145      146       154  \n",
       "0 -1.165737 -0.105657 -0.028724 -0.45347 -0.45347 -0.788655  \n",
       "1 -1.165737 -0.105657 -0.028724 -0.45347 -0.45347 -0.788655  \n",
       "2 -1.165737 -0.105657 -0.028724 -0.45347 -0.45347 -0.788655  \n",
       "3 -1.165737 -0.105657 -0.028724 -0.45347 -0.45347 -0.788655  \n",
       "4 -1.165737 -0.105657 -0.028724 -0.45347 -0.45347 -0.788655  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe powered gaussian \n",
    "\n",
    "PX2df = pd.DataFrame(poweredX2, columns= Xselected.columns)\n",
    "\n",
    "PX2df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>133</th>\n",
       "      <th>138</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          5         6         8         9   14   15   16   18   20   26  ...  \\\n",
       "0  0.000064  0.000064  0.009150  0.009150  1.0  1.0  1.0  1.0  1.0  1.0  ...   \n",
       "1  0.000012  0.000012  0.000000  0.000000  1.0  1.0  1.0  1.0  1.0  1.0  ...   \n",
       "2  0.036308  0.036308  0.070588  0.070588  1.0  1.0  1.0  1.0  1.0  1.0  ...   \n",
       "3  0.005238  0.005238  0.094771  0.094771  1.0  1.0  1.0  1.0  1.0  1.0  ...   \n",
       "4  0.035887  0.035887  0.070588  0.070588  1.0  1.0  1.0  1.0  1.0  1.0  ...   \n",
       "\n",
       "   133  138  140  141  142  143  144  145  146  154  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe normalised range 0_1\n",
    "\n",
    "NX3df = pd.DataFrame(scaled0_1, columns= Xselected.columns)\n",
    "NX3df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       0.635083\n",
       "6       0.635083\n",
       "8       1.259153\n",
       "9       1.259153\n",
       "14    -67.957971\n",
       "         ...    \n",
       "143     9.370956\n",
       "144    34.786323\n",
       "145     1.751773\n",
       "146     1.751773\n",
       "154     1.512698\n",
       "Length: 78, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PX2df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.899257065741918"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(PX2df.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_only = pd.DataFrame(normalizedX2, columns = Xselected.columns)\n",
    "Y.columns=['Y']\n",
    "\n",
    "norm_only=norm_only.join(Y)\n",
    "\n",
    "norm_csv = norm_only.to_csv (r'C:\\Users\\Student\\Git\\AML_project\\datasets\\norm_csv1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.22068920e-04 2.33816673e-04 2.69676922e-02 4.80630979e-03\n",
      " 5.06540146e-04 2.83710085e-02 4.37740027e-03 2.86934686e-03\n",
      " 6.99570277e-02 6.79465964e-04 1.08167379e-03 1.79456538e-02\n",
      " 1.36351272e-02 1.14109943e-01 1.59371181e-03 1.55163321e-01\n",
      " 6.26582968e-02 2.72093337e-03 1.11050348e-02 2.89845925e-02\n",
      " 4.01769873e-04 2.58986079e-03 5.96794724e-02 1.40816554e-02\n",
      " 1.68420935e-02 7.65778159e-02 1.92908463e-04 3.09713176e-02\n",
      " 8.18854220e-04 1.49382154e-03 1.64329204e-03 4.83758730e-04\n",
      " 2.34452053e-02 5.03957332e-04 1.38860122e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.32081554e-02\n",
      " 2.37665064e-03 7.10226467e-04 1.10234935e-02 0.00000000e+00\n",
      " 5.70138112e-04 9.83471006e-05 0.00000000e+00 1.13103784e-04\n",
      " 4.13778180e-03 1.34551412e-02 3.00882545e-04 8.90206441e-03\n",
      " 2.59938691e-04 1.72470976e-04 0.00000000e+00 0.00000000e+00\n",
      " 1.30304530e-02 2.41340972e-03 4.61065333e-03 2.54908225e-03\n",
      " 1.35743608e-02 2.74278488e-06 2.24411378e-06 9.15314397e-03\n",
      " 1.25032146e-03 6.49366914e-03 6.87671904e-04 4.50276685e-05\n",
      " 0.00000000e+00 1.34173325e-03 2.99642762e-02 2.42918910e-04\n",
      " 2.03789112e-03 1.69524952e-03 0.00000000e+00 3.76795803e-06\n",
      " 0.00000000e+00 5.39722278e-02]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(normalizedX2,Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ed32cb12d3a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "sorted((importance, col) for (col, importance) in enumerate(model.feature_importances_))[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_only.columns[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Reduced dataset (down to 78 features) by removing zero variance features - dataset 1\n",
    "\n",
    "- Xselected\n",
    "\n",
    "Dataset 1 + normalised the dataset by rescaling each row to add up to length one - dataset 2\n",
    "\n",
    "- NX2df\n",
    "\n",
    "Dataset 1 + rescaling each feature between 0 to 1 - dataset 3\n",
    "\n",
    "- NX3df \n",
    "\n",
    "Dataset 1 + transform the datset to be gaussian like (mean=0 abd s.d=1) - dataset 4\n",
    "\n",
    "- PX2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 152 features per sample; expecting 78",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-26a139ca02f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXselected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 270\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 152 features per sample; expecting 78"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model = LogisticRegression()\n",
    "model.fit(Xselected,Y)\n",
    "predictions = model.predict(Xtest)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ytest,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost & XgBoost classifier with Kbest feature selection on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_validate\n",
    "from numpy import random, arange\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature         Score\n",
      "25      71  32124.682195\n",
      "16      51  28936.000138\n",
      "22      67  28321.490224\n",
      "13      47  24346.021809\n",
      "77     154  13311.733744\n",
      "15      50  12317.666392\n",
      "2        8  12076.290588\n",
      "3        9  12076.290588\n",
      "23      68   7911.296191\n",
      "34      82   7720.479234\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = Xselected, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,34))\n",
    "import numpy \n",
    "X_top_features = Xselected.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([16.88924599, 18.57903004, 19.61032724, 16.98861003, 17.83964992]),\n",
       " 'score_time': array([0.01466632, 0.0195148 , 0.01424694, 0.01427627, 0.0139029 ]),\n",
       " 'test_score': array([0.99953632, 0.9994848 , 0.99963932, 0.99948475, 0.99969085])}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes =  arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]\n",
    "\n",
    "cb = CatBoostClassifier(verbose=False, early_stopping_rounds=50)\n",
    "cb_cv = cross_validate(cb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "cb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.38882828, 2.80635309, 2.65520096, 2.61705399, 2.46459889]),\n",
       " 'score_time': array([0.0297358 , 0.03513479, 0.03065014, 0.03140807, 0.03049994]),\n",
       " 'test_score': array([0.99783617, 0.99835137, 0.99773289, 0.99762984, 0.99824815])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = XGBClassifier(verbosity=0)\n",
    "gb_cv = cross_validate(gb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "gb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost & XgBoost classifier with Kbest feature selection on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature        Score\n",
      "25      71  7372.324026\n",
      "22      67  6638.208530\n",
      "16      51  6420.835610\n",
      "13      47  5284.319604\n",
      "77     154  2702.397952\n",
      "15      50  2624.375281\n",
      "2        8  2425.541023\n",
      "3        9  2425.541023\n",
      "23      68  2162.037565\n",
      "27      73  1818.607457\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = NX2df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,27))\n",
    "X_top_features = NX2df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Classifier dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([19.48945689, 20.40593696, 18.60622501, 19.67188191, 21.3007338 ]),\n",
       " 'score_time': array([0.01459622, 0.01379013, 0.01371908, 0.01435018, 0.01378512]),\n",
       " 'test_score': array([0.99747553, 0.99726945, 0.99701154, 0.99690849, 0.99696002])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(verbose=False, early_stopping_rounds=50)\n",
    "cb_cv = cross_validate(cb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "cb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost Classifier dataset 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.14661694, 4.41106415, 4.12002206, 4.19900227, 4.16188002]),\n",
       " 'score_time': array([0.03509212, 0.03049994, 0.03502893, 0.03120995, 0.03449702]),\n",
       " 'test_score': array([0.99690881, 0.99696033, 0.99634171, 0.99654782, 0.99690849])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = XGBClassifier(verbosity=0)\n",
    "gb_cv = cross_validate(gb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "gb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost & XgBoost classifier with Kbest feature selection on dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature         Score\n",
      "25      71  32124.682195\n",
      "16      51  28936.000138\n",
      "22      67  28321.490224\n",
      "13      47  24346.021809\n",
      "77     154  13311.733744\n",
      "15      50  12317.666392\n",
      "2        8  12076.290588\n",
      "3        9  12076.290588\n",
      "23      68   7911.296191\n",
      "34      82   7720.479234\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = NX3df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,34))\n",
    "X_top_features = NX3df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Classifier dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([18.59923005, 16.90425181, 16.79899788, 17.6864748 , 18.00517201]),\n",
       " 'score_time': array([0.01949787, 0.0240171 , 0.01366305, 0.01427627, 0.01497293]),\n",
       " 'test_score': array([0.9997424 , 0.9997424 , 0.99953627, 0.99969085, 0.9991756 ])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(verbose=False, early_stopping_rounds=50)\n",
    "cb_cv = cross_validate(cb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "cb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost Classifier dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.54442596, 2.60541296, 2.54903793, 2.38389492, 2.48685789]),\n",
       " 'score_time': array([0.03097701, 0.03572512, 0.02722311, 0.03145814, 0.026968  ]),\n",
       " 'test_score': array([0.99804225, 0.99783617, 0.99778442, 0.99809357, 0.99747527])}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = XGBClassifier(verbosity=0)\n",
    "gb_cv = cross_validate(gb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "gb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost & XgBoost classifier with Kbest feature selection (F-Score because we have negative values) on dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature          Score\n",
      "22      67  269542.333666\n",
      "32      79  163819.390690\n",
      "25      71   97844.145325\n",
      "13      47   78746.577388\n",
      "15      50   71820.406311\n",
      "16      51   71691.363749\n",
      "29      76   67959.074904\n",
      "28      75   58056.238169\n",
      "23      68   39952.836596\n",
      "0        5   38924.936512\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_selection\n",
    "Xtrain, Ytrain = PX2df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((22,32,25,13,16,15,29,28,23,0))\n",
    "X_top_features = PX2df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Classifier dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([20.41070414, 18.77909589, 16.35451603, 21.41363525, 18.47896409]),\n",
       " 'score_time': array([0.01422501, 0.01888609, 0.0143249 , 0.0139761 , 0.01378512]),\n",
       " 'test_score': array([0.98892324, 0.98887172, 0.98753092, 0.98881904, 0.98825227])}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(verbose=False, early_stopping_rounds=50)\n",
    "cb_cv = cross_validate(cb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "cb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost Classifier dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.50444603, 2.47596002, 2.46800709, 2.4801631 , 2.45774913]),\n",
       " 'score_time': array([0.03327894, 0.03611183, 0.03575087, 0.03327203, 0.0341959 ]),\n",
       " 'test_score': array([0.9867594 , 0.98578053, 0.98495466, 0.98670651, 0.98650041])}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = XGBClassifier(verbosity=0)\n",
    "gb_cv = cross_validate(gb, X_cv, Y_cv, cv=5, scoring=\"accuracy\")\n",
    "gb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier with SelectKBest and all the four datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectKbest on the test set so we can test our models on them to get a more clear indication of our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature          Score\n",
      "66      69  253612.537678\n",
      "72      75  103422.563125\n",
      "64      67   60099.740490\n",
      "76      79   54602.096207\n",
      "35      38   53382.778304\n",
      "47      50   50860.969206\n",
      "48      51   50711.492888\n",
      "44      47   34731.734788\n",
      "78      81   24655.530821\n",
      "5        8   12670.064665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [  0   1   2   7   8   9  10  14  16  18  19  20  21  22  24  25  27  28\n",
      "  29  30  31  32  33  34  36  37  38  39  41  42  43  46  50  51  52  53\n",
      "  54  55  56  57  60  62  71  80  81  82  83  84  85  88  89  92  93  94\n",
      "  96  97  98  99 100 110 111 112 113 114 121 128 129 130 131 132 133 134\n",
      " 135 136 144 146 147 148 149 150] are constant.\n",
      "  UserWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_selection\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(k=10)\n",
    "fit = bestfeatures.fit(Xtest,Ytest)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtest.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((66,72,64,76,35,47,48,44,78,5))\n",
    "X_top_features = Xtest.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytest.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "Xtest_cv = X_top_features.iloc[indexes,:]\n",
    "Ytest_cv = Ytest.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature         Score\n",
      "25      71  32124.682195\n",
      "16      51  28936.000138\n",
      "22      67  28321.490224\n",
      "13      47  24346.021809\n",
      "77     154  13311.733744\n",
      "15      50  12317.666392\n",
      "2        8  12076.290588\n",
      "3        9  12076.290588\n",
      "23      68   7911.296191\n",
      "34      82   7720.479234\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = Xselected, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,34))\n",
    "import numpy \n",
    "X_top_features = Xselected.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_cv,Y_cv)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(Xtest_cv)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Ytest_cv, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature        Score\n",
      "25      71  7372.324026\n",
      "22      67  6638.208530\n",
      "16      51  6420.835610\n",
      "13      47  5284.319604\n",
      "77     154  2702.397952\n",
      "15      50  2624.375281\n",
      "2        8  2425.541023\n",
      "3        9  2425.541023\n",
      "23      68  2162.037565\n",
      "27      73  1818.607457\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = NX2df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,27))\n",
    "X_top_features = NX2df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_cv,Y_cv)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(Xtest_cv)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Ytest_cv, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature         Score\n",
      "25      71  32124.682195\n",
      "16      51  28936.000138\n",
      "22      67  28321.490224\n",
      "13      47  24346.021809\n",
      "77     154  13311.733744\n",
      "15      50  12317.666392\n",
      "2        8  12076.290588\n",
      "3        9  12076.290588\n",
      "23      68   7911.296191\n",
      "34      82   7720.479234\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = NX3df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((25,16,22,13,77,15,2,3,23,34))\n",
    "X_top_features = NX3df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_cv,Y_cv)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(Xtest_cv)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Ytest_cv, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature          Score\n",
      "22      67  269542.333666\n",
      "32      79  163819.390690\n",
      "25      71   97844.145325\n",
      "13      47   78746.577388\n",
      "15      50   71820.406311\n",
      "16      51   71691.363749\n",
      "29      76   67959.074904\n",
      "28      75   58056.238169\n",
      "23      68   39952.836596\n",
      "0        5   38924.936512\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain = PX2df, Y\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(k=10)\n",
    "fit = bestfeatures.fit(Xtrain,Ytrain)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(Xtrain.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    " #naming the dataframe columns\n",
    "featureScores.columns = ['feature','Score'] \n",
    " #print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = set((22,32,25,13,16,15,29,28,23,0))\n",
    "X_top_features = PX2df.iloc[:, list(selected_features)]\n",
    "indexes = numpy.arange(Ytrain.shape[0])\n",
    "numpy.random.shuffle(indexes)\n",
    "X_cv = X_top_features.iloc[indexes,:]\n",
    "Y_cv = Ytrain.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_cv,Y_cv)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(Xtest_cv)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Ytest_cv, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
